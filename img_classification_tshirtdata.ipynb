{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading all required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "Reading data files(csv files which contain image urls)\n",
    "\n",
    "\n",
    "data=pd.read_csv('Images_Train.csv')\n",
    "t_data= pd.read_csv('Images_Test.csv')\n",
    "\n",
    "\n",
    "data.shape\n",
    "\n",
    "t_data.shape\n",
    "\n",
    "#Displaying few top 5 records of test data\n",
    "data.head()\n",
    "\n",
    "#Displaying few top 5 records of test data\n",
    "t_data.head()\n",
    " \n",
    "Preprocessing\n",
    "#Handing NA values\n",
    "train_data = data.dropna(subset=['Link_to_the_image'],  how= 'any') #dropping empty link rows in train data\n",
    "train_data.reset_index()\n",
    "train_data.shape\n",
    " \n",
    "test_data = t_data.dropna(subset=['Link_to_the_image'],  how= 'any') #dropping empty link rows in test data\n",
    "test_data.reset_index()\n",
    "test_data.shape\n",
    " \n",
    "#Displaying row count for all classes in train data\n",
    "\n",
    "print(train_data.Sub_category.value_counts()) \n",
    "print(len(train_data.Sub_category.unique()))\n",
    "\n",
    " \n",
    "#Displaying row count for all classes in test data\n",
    "print(test_data.Sub_category.value_counts())\n",
    "print(len(test_data.Sub_category.unique()))\n",
    " \n",
    "%matplotlib inline\n",
    "#checking the distribution for the total number of classes in train data\n",
    "plt.figure() \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data.Sub_category.value_counts().plot(kind='bar',\n",
    "                                  figsize=(8,6),\n",
    "                                  color=[\"Green\"],\n",
    "                                  alpha = 0.7,\n",
    "                                  fontsize=10)\n",
    "\n",
    "plt.title('Train data Tshirt graphic types')\n",
    "plt.grid()\n",
    "\n",
    "plt.xticks(rotation =90)\n",
    "\n",
    " \n",
    "\n",
    "#checking the distribution for the total number of classes in test data\n",
    "\n",
    "plt.figure()\n",
    "test_data.Sub_category.value_counts().plot(kind='bar',\n",
    "                                  figsize=(8,6),\n",
    "                                  color=[\"Green\"],\n",
    "                                  alpha = 0.7,\n",
    "                                  fontsize=10)\n",
    "plt.title('Test data Tshirt graphic types')\n",
    "plt.grid()\n",
    "\n",
    "plt.xticks(rotation =90)\n",
    " \n",
    "We have class Imbalance and one Unknown Class in Test. We have to take care of both. **\n",
    "# Handling class Imbalance\n",
    "series = pd.value_counts(train_data.Sub_category) \n",
    "\n",
    "mask = (series/series.sum() * 100).lt(2.5)\n",
    "train_data['Sub_category']=np.where(train_data['Sub_category'].isin(series[mask].index),'Other',train_data['Sub_category'])\n",
    "train_data['Sub_category'].value_counts()\n",
    " \n",
    "#considering all high frequency labels from train data and changed all the low frequency label names as 'other' \n",
    "train_labels = train_data['Sub_category'].unique().tolist()\n",
    "train_labels\n",
    " \n",
    "reading images for model building\n",
    "#defining function for reading the images\n",
    "size= 299\n",
    "def read_image(f):\n",
    "    im = Image.open(f)\n",
    "    im = im.resize((size, size), PIL.Image.NEAREST)\n",
    "    im = np.asarray(im, dtype='float64')\n",
    "    return(im)\n",
    "\n",
    "img_files = []\n",
    "for root, dirs, files in os.walk('/home/B49gpu1/2364/Train_images/'):\n",
    "    img_files.extend(files)\n",
    "im = read_image('Train_images/img_1.png')\n",
    "print(im.shape)\n",
    " \n",
    "#printing the image file names\n",
    "print(img_files[:10])\n",
    " \n",
    "n_files = len(img_files)\n",
    "print('Total number of images:', n_files) #checking total number of images\n",
    " \n",
    "#Converting Target to Numeric\n",
    "\n",
    "train_labels = list(train_data.Sub_category.unique()) # saving all the target classes from train data\n",
    " \n",
    "#sorting the lables alphabitical\n",
    "train_labels.sort()\n",
    "print(train_labels)\n",
    " \n",
    "#creating the target labels dictonary to label encoding those manually\n",
    "y_dict = {'Sub_category' : {train_labels[i] : i for i in range(0, len(train_labels))}}\n",
    "y_dict\n",
    " \n",
    "#replacing the encoding values of target in the train data\n",
    "train_data.replace(y_dict,inplace=True)\n",
    "train_data.head()\n",
    " \n",
    "Reading Images\n",
    "\n",
    "i=0\n",
    "x_train = []\n",
    "y_train = []\n",
    "print('Reading train images ...')\n",
    "for file in img_files:\n",
    "    im = read_image(' /Train_images/'+file)\n",
    "    x_train.append(im)\n",
    "    i+=1\n",
    "    \n",
    "y_train= train_data.Sub_category.tolist() \n",
    "\n",
    "#Reading train images ...\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "print(x_train.shape, 'x_train Shape')\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "print(y_train.shape, 'y_train Shape')\n",
    " \n",
    "# checking image count\n",
    "print(i)\n",
    " \n",
    "#Model Building\n",
    "#Model\n",
    "\n",
    "#We will use the available pretrained models in Keras, trained over ImageNet dataset and we will fine tune it for our task. This is because the top layers learn simple basic features and we need not to train those layers and it can be directly applied to our task.\n",
    "\n",
    "#Note that the input image format for this model is different than for the VGG16 and ResNet models (299x299 instead of 224x224),\n",
    "\n",
    "#Arguments\n",
    "\n",
    "#include_top: whether to include the fully-connected layer at the top of the network.\n",
    "\n",
    "#weights: one of None (random initialization), 'imagenet' (pre-training on ImageNet),\n",
    "\n",
    "### Get inception architecture from keras.applications\n",
    "from keras.applications.inception_v3 import InceptionV3,GlobalAveragePooling2D,decode_predictions\n",
    "\n",
    "trained_model = InceptionV3(include_top=False,weights='imagenet')\n",
    "# print(trained_model.summary())\n",
    "\n",
    "x = trained_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(300,activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "pred_inception= Dense(9,activation='softmax')(x)\n",
    "model = Model(inputs=trained_model.input,outputs=pred_inception)\n",
    "# print(model.summary())\n",
    "#making the layers of inception non-trainable\n",
    "for layer in trained_model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "#compiling the model\n",
    "adam = Adam(lr=0.003)\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=adam)\n",
    "#fitting the model\n",
    "Model_1=model.fit(x_train,y_train,epochs=5,batch_size=100,validation_split=0.2)\n",
    " \n",
    "    \n",
    "    \n",
    "# confusion matrix\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#prediction_train=model.predict(x_train)\n",
    "#print(confusion_matrix(y_train,prediction_train))\n",
    "#checking Accuracy curves for the model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "%matplotlib inline\n",
    "fig1 = plt.figure()\n",
    "plt.plot(Model_1.history['acc'],'r',linewidth=3.0)\n",
    "plt.plot(Model_1.history['val_acc'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=12)\n",
    "plt.ylabel('Accuracy',fontsize=12)\n",
    "plt.title('Accuracy Curves ',fontsize=16)\n",
    "fig1.savefig('accuracy.png')\n",
    "plt.show()\n",
    "\n",
    "##Evaluate Test Data\n",
    "# Manually Handling one extra class in Test (changing S\n",
    "ports and Team Jercy to Sports)\n",
    "\n",
    "test_data['Sub_category'].replace(\n",
    "    to_replace=['Sports and Team Jersey'],\n",
    "    value='Sports',\n",
    "    inplace=True\n",
    ")\n",
    " \n",
    "#considering all high frequency labels from test data and changed all the low frequency label names as 'other' \n",
    "\n",
    "test_data['Sub_category']=np.where(np.isin(test_data['Sub_category'], train_labels),test_data['Sub_category'],'Other')\n",
    "test_data['Sub_category'].unique()\n",
    " \n",
    "\n",
    "\n",
    "#checking counts of labels in test data after modification\n",
    "test_data['Sub_category'].value_counts()\n",
    " \n",
    "#Converting them into numeric.\n",
    "test_data.replace(y_dict,inplace=True)\n",
    "test_data.head()\n",
    " \n",
    "# Varifying Target Variable\n",
    "\n",
    "test_data.Sub_category.unique()\n",
    " \n",
    "#Reading Test Images\n",
    "\n",
    "img_files_test = []\n",
    "for root, dirs, files in os.walk(' /Test_images/'):\n",
    "    img_files_test.extend(files)\n",
    "i=0\n",
    "x_test = []\n",
    "y_test = []\n",
    "print('Reading test images ...')\n",
    "for file in img_files_test:\n",
    "    im = read_image('/home/B49gpu1/2364/Test_images/'+file)\n",
    "    x_test.append(im)\n",
    "    i+=1\n",
    "    \n",
    "y_test= test_data.Sub_category.tolist() \n",
    "\n",
    "x_test = np.array(x_test)\n",
    "print(x_test.shape, 'x_test Shape')\n",
    "\n",
    "y_test = to_categorical(y_test)\n",
    "print(y_test.shape, 'y_test Shape')\n",
    " \n",
    "# checking image count\n",
    "print(i)\n",
    " \n",
    "model.evaluate(x_test,y_test)\n",
    " \n",
    "model.save(filepath='image_model_2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
